{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a039f5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "XGBoost Library (libxgboost.so) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libgomp.so for UNIX-like OSes)\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['libgomp.so.1: cannot open shared object file: No such file or directory']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_247/33650319.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTimeSeriesSplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_absolute_percentage_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrabit\u001b[0m                   \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;31m# load the XGBoost library globally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;34m'libgomp.so for UNIX-like OSes)\\n'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;34m'  * You are running 32-bit Python on a 64-bit OS\\n'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             'Error message(s): {}\\n'.format(os_error_list))\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_log_callback_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: XGBoost Library (libxgboost.so) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libgomp.so for UNIX-like OSes)\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['libgomp.so.1: cannot open shared object file: No such file or directory']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8bb2ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost==1.0.2 in /usr/local/lib/python3.7/site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from xgboost==1.0.2) (1.18.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/site-packages (from xgboost==1.0.2) (1.7.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost==1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a36e74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = pd.read_csv(\"demand_hourly.csv\")\n",
    "tss = TimeSeriesSplit(n_splits=5, test_size=24*60, gap=24)\n",
    "df = demand.sort_values(by=['start_time_year', 'start_time_month', \n",
    "                            'start_time_day', 'start_time_hour'])\n",
    "df = df.drop(columns=['Unnamed: 0', 'duration_sec']).reset_index(drop=True)\n",
    "\n",
    "standard_stations = pd.read_csv(\"stations_with_clusters.csv\")\n",
    "weather_data = pd.read_csv(\"weather_data.csv\")\n",
    "\n",
    "df = df.merge(standard_stations[['station_name', 'clusters']].rename(columns={\n",
    "    \"station_name\":'start_station_name'}), on=[\"start_station_name\"])\n",
    "\n",
    "df = df[df.groupby('start_station_name')['start_station_name'].transform('size') >= 1000]\n",
    "\n",
    "latest_trips = df.groupby('start_station_name').nth(-1)\n",
    "earliest_trips = df.groupby('start_station_name').nth(0)\n",
    "\n",
    "\n",
    "recently_operational_stations = latest_trips[(latest_trips['start_time_year'] == 2022) & \n",
    "                                             (latest_trips['start_time_month'] >= 8)].index\n",
    "\n",
    "stations_operational_since_2021 = earliest_trips[(earliest_trips['start_time_year'] == 2021)].index\n",
    "df = df[df['start_station_name'].isin(stations_operational_since_2021)].reset_index(drop=True)\n",
    "\n",
    "column_name = \"start_time\"\n",
    "conversion_dict_daily = dict(year= df[f'{column_name}_year'],\n",
    "                           month=df[f'{column_name}_month'],\n",
    "                           day=  df[f'{column_name}_day'],\n",
    "                           hour=  df[f'{column_name}_hour']\n",
    "                        )\n",
    "df['time'] = pd.to_datetime(conversion_dict_daily).astype(str)\n",
    "\n",
    "df = df.merge(weather_data[['temp', 'dwpt', \"rhum\", \"prcp\", \"wdir\", \"wspd\", \"pres\", \"coco\", \"centroid\", 'time']].rename(columns={\n",
    "    \"centroid\":\"clusters\"\n",
    "}), on=['clusters', \"time\"])\n",
    "\n",
    "df.loc[df['prcp'].isna(), 'prcp'] = 0.0\n",
    "df.loc[df['pres'].isna(), 'pres'] = df['pres'].median()\n",
    "df.loc[df['coco'].isna(), 'coco'] = df['coco'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d757a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lags(df, target, identifier):\n",
    "    df_res = pd.DataFrame()\n",
    "    print(target)\n",
    "    for ii in df[identifier].unique():\n",
    "        df_current = df[df[\"start_station_name\"]==ii]\n",
    "        df_current.index = df_current['time']\n",
    "        df_current.index = pd.to_datetime(df_current.index)\n",
    "        target_map = df_current[target].to_dict()\n",
    "        df_current[f\"{target}_lag_1_h\"] = (df_current.index - pd.Timedelta('1 hours')).map(target_map)\n",
    "        df_current[f\"{target}_lag_2_h\"] = (df_current.index - pd.Timedelta('2 hours')).map(target_map)\n",
    "        df_current[f\"{target}_lag_24_h\"] = (df_current.index - pd.Timedelta('24 hours')).map(target_map)\n",
    "        if target == \"demand\":\n",
    "            df_current[f\"{target}_lag_1_h\"] = df_current[f\"{target}_lag_1_h\"].fillna(0)\n",
    "            df_current[f\"{target}_lag_2_h\"] = df_current[f\"{target}_lag_2_h\"].fillna(0)\n",
    "            df_current[f\"{target}_lag_24_h\"] = df_current[f\"{target}_lag_24_h\"].fillna(0)\n",
    "        else:\n",
    "            df_current[f\"{target}_lag_1_h\"] = df_current[f\"{target}_lag_1_h\"].interpolate().fillna(0)\n",
    "            df_current[f\"{target}_lag_2_h\"] = df_current[f\"{target}_lag_2_h\"].interpolate().fillna(0)\n",
    "            df_current[f\"{target}_lag_24_h\"] = df_current[f\"{target}_lag_24_h\"].interpolate().fillna(0)\n",
    "        df_res = df_res.append(df_current)\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673f833d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = add_lags(df, \"demand\", identifier='start_station_name')\n",
    "df = add_lags(df, \"temp\", identifier='start_station_name')\n",
    "df = add_lags(df, \"prcp\", identifier='start_station_name')\n",
    "df = add_lags(df, \"rhum\", identifier='start_station_name')\n",
    "df = add_lags(df, \"wspd\", identifier='start_station_name')\n",
    "\n",
    "df = df.sort_values(by=['start_time_year', 'start_time_month', \n",
    "                        'start_time_day', 'start_time_hour']).drop(\n",
    "    columns=['time']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0556ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    if 'lag' in i:\n",
    "        print((df[(df['start_station_name'] == \"1st St at Folsom St\")][i].interpolate().isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdca9077",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    print(i)\n",
    "    print(sum(df[i].isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b034eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "del demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0531854",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9741a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.sort_index()\n",
    "\n",
    "fig, axs = plt.subplots(5, 1, figsize=(15, 15), sharex=True)\n",
    "\n",
    "fold = 0\n",
    "for train_idx, val_idx in tss.split(df):\n",
    "    train = df.iloc[train_idx]\n",
    "    test = df.iloc[val_idx]\n",
    "    train['demand'].plot(ax=axs[fold],\n",
    "                          label='Training Set',\n",
    "                          title=f'Data Train/Test Split Fold {fold}')\n",
    "    test['demand'].plot(ax=axs[fold],\n",
    "                         label='Test Set')\n",
    "    axs[fold].axvline(test.index.min(), color='black', ls='--')\n",
    "    fold += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4c9f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = TimeSeriesSplit(n_splits=5, test_size=24*5*df['start_station_name'].nunique(), gap=24)\n",
    "df = df.sort_index()\n",
    "\n",
    "fold = 0\n",
    "preds = pd.DataFrame()\n",
    "rmse = []\n",
    "mape = []\n",
    "le = preprocessing.LabelEncoder()\n",
    "scaler = MinMaxScaler(feature_range=(1, 2))\n",
    "SCALER_FEATURES = [\"start_time_year\", \"start_time_month\", \n",
    "                   \"start_time_day\", \"start_time_hour\", \n",
    "                   \"start_time_week\", \"start_time_quarter\",\n",
    "                   \"start_time_dayofweek\",\n",
    "                   \"temp\", \"dwpt\", \"rhum\", \"prcp\", \"wdir\",\n",
    "                   \"wspd\", \"pres\",\"coco\",\n",
    "                   \"demand_lag_1_h\", \"demand_lag_2_h\", \n",
    "                   \"demand_lag_24_h\", \"temp_lag_1_h\", \n",
    "                   \"temp_lag_2_h\", \"temp_lag_24_h\",\n",
    "                   \"prcp_lag_1_h\", \"prcp_lag_2_h\",\n",
    "                   \"prcp_lag_24_h\", \"rhum_lag_1_h\",\n",
    "                   \"rhum_lag_2_h\", \"rhum_lag_24_h\", \"wspd_lag_1_h\", \n",
    "                   \"wspd_lag_2_h\",\"wspd_lag_24_h\"]\n",
    "target_scaler = MinMaxScaler(feature_range=(1, 2))\n",
    "df[SCALER_FEATURES] = scaler.fit_transform(df[SCALER_FEATURES])\n",
    "df[['demand']] = target_scaler.fit_transform(df[['demand']])\n",
    "df['start_station_name'] = le.fit_transform(df['start_station_name'])\n",
    "df['is_holiday'] = df['is_holiday'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b388dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "24*5*df['start_station_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69d3ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "24*10*df['start_station_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1884ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for train_idx, val_idx in tss.split(df):\n",
    "\n",
    "    train = df.iloc[train_idx]\n",
    "    test = df.iloc[val_idx]\n",
    "\n",
    "\n",
    "    FEATURES = [\"start_station_name\", \n",
    "                \"start_time_year\",\n",
    "                \"start_time_month\",\n",
    "                \"start_time_day\",\n",
    "                \"start_time_hour\",\n",
    "                \"start_time_week\",\n",
    "                \"start_time_quarter\",\n",
    "                \"start_time_dayofweek\",\n",
    "                \"is_holiday\",\n",
    "                \"clusters\",\n",
    "                \"temp\",\n",
    "                \"dwpt\",\n",
    "                \"rhum\",\n",
    "                \"prcp\",\n",
    "                \"wdir\",\n",
    "                \"wspd\",\n",
    "                \"pres\",\n",
    "                \"coco\",\n",
    "                \"demand_lag_1_h\",\n",
    "                \"demand_lag_2_h\",\n",
    "                \"demand_lag_24_h\",\n",
    "                \"temp_lag_1_h\",\n",
    "                \"temp_lag_2_h\",\n",
    "                \"temp_lag_24_h\",\n",
    "                \"prcp_lag_1_h\",\n",
    "                \"prcp_lag_2_h\",\n",
    "                \"prcp_lag_24_h\",\n",
    "                \"rhum_lag_1_h\",\n",
    "                \"rhum_lag_2_h\",\n",
    "                \"rhum_lag_24_h\",\n",
    "                \"wspd_lag_1_h\",\n",
    "                \"wspd_lag_2_h\",\n",
    "                \"wspd_lag_24_h\"\n",
    "                ]\n",
    "    TARGET = 'demand'\n",
    "\n",
    "    X_train = train[FEATURES]\n",
    "    y_train = train[TARGET]\n",
    "\n",
    "    X_test = test[FEATURES]\n",
    "    y_test = test[TARGET]\n",
    "\n",
    "    reg = xgboost.XGBRegressor()\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    preds_out = X_test.copy()\n",
    "    preds_out['actual_demand'] = y_test\n",
    "    preds_out['pred'] = y_pred\n",
    "    preds = preds.append(preds_out)\n",
    "    rmse_score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mape_score = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    rmse.append(rmse_score)\n",
    "    mape.append(mape_score)\n",
    "    print(rmse_score)\n",
    "    print(mape_score)\n",
    "    print(preds.head())\n",
    "    print(preds.tail())\n",
    "    \n",
    "print(f\"Mean RMSE: {np.mean(rmse)}\")\n",
    "print(f\"Mean MAPE: {np.mean(mape)}\")\n",
    "del df\n",
    "del X_train\n",
    "del y_train\n",
    "del X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b965d814",
   "metadata": {},
   "outputs": [],
   "source": [
    "suf = \"_dec_2022_weather_lags\"\n",
    "\n",
    "#preds.to_csv(f\"test_predictions{suf}.csv\")\n",
    "#del preds\n",
    "#\n",
    "#filename = f'demand_model{suf}.sav'\n",
    "#joblib.dump(reg, filename)\n",
    "#del reg\n",
    "\n",
    "filename = f'target_scaler{suf}.sav'\n",
    "joblib.dump(target_scaler, filename)\n",
    "del target_scaler\n",
    "\n",
    "filename = f'scaler{suf}.sav'\n",
    "joblib.dump(scaler, filename)\n",
    "del scaler\n",
    "\n",
    "filename = f'label_encoder{suf}.sav'\n",
    "joblib.dump(le, filename)\n",
    "del le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4fe6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2882d3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds['demand'] = preds['actual_demand']\n",
    "#preds[SCALER_FEATURES] = scaler.inverse_transform(preds[SCALER_FEATURES])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
